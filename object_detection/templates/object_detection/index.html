<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ClearPath: Object Detection</title>
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0-alpha1/dist/css/bootstrap.min.css" rel="stylesheet">
    <style>
        /* General Styles */
        body {
            background: linear-gradient(to bottom, #d9e4f5, #f1f8ff);
            font-family: 'Arial', sans-serif;
            color: #333;
            margin: 0;
            padding: 0;
        }

        /* Header */
        header {
            text-align: center;
            padding: 3rem 0;
            background: linear-gradient(to bottom, rgba(173, 216, 230, 0.8), rgba(240, 248, 255, 0.6));
            color: #003366;
            margin-bottom: 2rem;
            box-shadow: 0px 4px 10px rgba(0, 0, 0, 0.2);
        }

        header h1 {
            font-size: 3rem;
            font-weight: bold;
            margin: 0;
        }

        header p {
            font-size: 1.2rem;
            margin: 0.5rem 0 0;
            color: #003366;
        }

        /* Container */
        .container {
            max-width: 800px;
            background: rgba(240, 248, 255, 0.9);
            margin: 0 auto;
            border-radius: 12px;
            padding: 2rem;
            box-shadow: 0px 4px 10px rgba(0, 0, 0, 0.2);
        }

        /* Landing Section */
        .landing-section h2 {
            font-size: 2.5rem;
            margin-bottom: 1rem;
            color: #003366;
        }

        .landing-section p.description {
            font-size: 1.2rem;
            margin-bottom: 2rem;
            color: #555;
        }

        /* Buttons */
        button {
            font-size: 1rem;
            padding: 0.8rem 1.5rem;
            border-radius: 5px;
            background-color: #0dcaf0;
            border: none;
            color: white;
            transition: transform 0.2s ease, box-shadow 0.2s ease;
        }

        button:hover {
            transform: scale(1.05);
            box-shadow: 0px 4px 10px rgba(0, 123, 255, 0.4);
        }

        button:disabled {
            opacity: 0.6;
            cursor: not-allowed;
        }

        /* Video Container */
        #video-container video {
            width: 100%;
            border: 3px solid #003366;
            border-radius: 10px;
            margin-top: 1.5rem;
            box-shadow: 0px 4px 8px rgba(0, 0, 0, 0.2);
        }

        #fallback-video {
            display: none;
        }

        /* Image Container */
        #image-container p {
            font-size: 1.2rem;
            color: #333;
            margin-top: 1.5rem;
        }

        /* Detected Objects */
        #detected-objects p {
            font-size: 1rem;
            color: #0056b3;
            margin-top: 1rem;
        }

        /* Footer */
        footer {
            text-align: center;
            padding: 1rem 0;
            background-color: rgba(240, 248, 255, 0.9);
            color: #003366;
            margin-top: 3rem;
            border-top: 1px solid rgba(0, 0, 139, 0.2);
        }

        /* Responsive Design */
        @media (max-width: 768px) {
            header h1 {
                font-size: 2.2rem;
            }

            header p {
                font-size: 1rem;
            }

            .container {
                padding: 1.5rem;
            }

            button {
                font-size: 0.9rem;
                padding: 0.6rem 1.2rem;
            }
        }
    </style>
</head>
<body>
    <header>
        <h1>ClearPath</h1>
        <p>Object Detection with Auditory Feedback</p>
    </header>

    <div class="container">
        <div class="landing-section text-center">
            <h2>Welcome to ClearPath</h2>
            <p class="description">Object detection and clear auditory feedback for visually impaired users.</p>
            <div class="d-flex justify-content-center mb-3">
                <button id="start-button" class="btn btn-primary mx-2">Start Camera</button>
                <button id="rotate-button" class="btn btn-secondary mx-2" disabled>Rotate Camera</button>
                <button id="stop-button" class="btn btn-danger mx-2" disabled>Stop Camera</button>
                <button id="detect-button" class="btn btn-success mx-2" disabled>Detect Objects</button>
            </div>
            <p id="status" class="mt-3 text-muted">Camera status: Not initialized</p>

            <div id="video-container" class="mt-4">
                <video id="video" autoplay playsinline></video>
                <video id="fallback-video" style="display: none;" autoplay loop>
                    <source src="fallback.mp4" type="video/mp4">
                    Your browser does not support the video tag.
                </video>
            </div>

            <div id="image-container" class="mt-4">
                <p id="no-image-text">No image detected yet.</p>
            </div>

            <div id="detected-objects"></div> <!-- Container for displaying detected objects -->
        </div>
    </div>

    <footer>
        <p>&copy; 2024 ClearPath. Accessibility is our priority.</p>
    </footer>

    <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0-alpha1/dist/js/bootstrap.bundle.min.js"></script>
    <script>
        const videoElement = document.getElementById('video');
        const fallbackVideoElement = document.getElementById('fallback-video');
        const startButton = document.getElementById('start-button');
        const rotateButton = document.getElementById('rotate-button');
        const stopButton = document.getElementById('stop-button');
        const detectButton = document.getElementById('detect-button');
        const statusElement = document.getElementById('status');
        const imageContainer = document.getElementById('image-container');
        const noImageText = document.getElementById('no-image-text');
        const detectedObjectsDiv = document.getElementById('detected-objects');
    
        let currentStream = null;
        let useFrontCamera = true;
        let detectedObjectTimeout = null;  // Variable to store the timeout reference
    
        // Start the camera
        async function startCamera() {
            try {
                const constraints = {
                    video: {
                        facingMode: useFrontCamera ? 'user' : 'environment'
                    }
                };
                const stream = await navigator.mediaDevices.getUserMedia(constraints);
                videoElement.srcObject = stream;
                currentStream = stream;
    
                statusElement.textContent = "Camera is active.";
                playAudioFeedback("Camera is now active.");
                rotateButton.disabled = false;
                stopButton.disabled = false;
                detectButton.disabled = false;
                startRealTimeDetection();  // Start real-time detection
            } catch (error) {
                console.error("Error accessing camera: ", error);
                handleCameraError();
            }
        }
    
        // Stop the camera
        function stopCamera() {
            if (currentStream) {
                currentStream.getTracks().forEach(track => track.stop());
                currentStream = null;
                videoElement.srcObject = null;
    
                statusElement.textContent = "Camera is stopped.";
                playAudioFeedback("Camera is now stopped.");
                rotateButton.disabled = true;
                stopButton.disabled = true;
                detectButton.disabled = true;
            }
        }
    
        // Handle camera error
        function handleCameraError() {
            statusElement.textContent = "Unable to access the camera. Playing a fallback video.";
            playAudioFeedback("Unable to open the camera. A video will play instead. Please try again later.");
            fallbackVideoElement.style.display = "block";
            videoElement.style.display = "none";
        }
    
        // Play audio feedback with a female voice
        function playAudioFeedback(message) {
            const utterance = new SpeechSynthesisUtterance(message);
            utterance.rate = 1.0;
            utterance.pitch = 1.0;
    
            const voices = speechSynthesis.getVoices();
            if (voices.length === 0) {
                speechSynthesis.onvoiceschanged = () => {
                    setVoiceToFemale(utterance);
                    speechSynthesis.speak(utterance);
                };
            } else {
                setVoiceToFemale(utterance);
                speechSynthesis.speak(utterance);
            }
        }
    
        // Set the voice to a female voice
        function setVoiceToFemale(utterance) {
            const voices = speechSynthesis.getVoices();
            const femaleVoice = voices.find(voice => voice.name.toLowerCase().includes('female'));
            if (femaleVoice) {
                utterance.voice = femaleVoice;
            }
        }
    
        // Rotate the camera
        rotateButton.addEventListener('click', () => {
            useFrontCamera = !useFrontCamera;
            stopCamera();
            startCamera();
            playAudioFeedback("Camera rotated.");
        });
    
        // Event listener for buttons
        startButton.addEventListener('click', startCamera);
        stopButton.addEventListener('click', stopCamera);
    
        detectButton.addEventListener('click', async () => {
            // Clear previously displayed detected objects
            detectedObjectsDiv.innerHTML = '';
            noImageText.style.display = "none"; 
            
            if (videoElement.srcObject) {
                // Capture a single frame from the video feed
                const canvas = document.createElement('canvas');
                const ctx = canvas.getContext('2d');
                canvas.width = videoElement.videoWidth;
                canvas.height = videoElement.videoHeight;
                ctx.drawImage(videoElement, 0, 0, canvas.width, canvas.height);
    
                // Convert the canvas image to a base64 string
                const base64Image = canvas.toDataURL('image/jpeg');
                console.log("Captured Image:", base64Image);  // Debugging line to check if the image is captured
    
                // Send the base64 image to the backend for object detection
                try {
                    const response = await fetch('http://127.0.0.1:5000/detect', {
                        method: 'POST',
                        headers: {
                            'Content-Type': 'application/json'
                        },
                        body: JSON.stringify({ image: base64Image })
                    });
    
                    const data = await response.json();
                    console.log("Backend response:", data);  // Debugging line to check the response from backend
    
                    // Check if detected objects are returned
                    if (data.objects && data.objects.length > 0) {
                        const objectCounts = countObjects(data.objects);
                        const riskLevels = classifyRiskLevels(objectCounts);
                        provideAuditoryFeedback(objectCounts, riskLevels);
                        displayDetectedObjects(objectCounts, riskLevels);
                    } else {
                        noImageText.style.display = "block";
                    }
                } catch (error) {
                    console.error("Error during detection:", error);
                    playAudioFeedback("Error in object detection.");
                }
            }
        });
    
        // Count the occurrences of each detected object
        function countObjects(objects) {
            const counts = {};
            objects.forEach(obj => {
                counts[obj] = (counts[obj] || 0) + 1;
            });
            return counts;
        }
    
        // Classify detected objects based on risk levels
        function classifyRiskLevels(objectCounts) {
            const riskLevels = {};
            Object.keys(objectCounts).forEach(obj => {
                if (obj === 'person' || obj === 'car' || obj === 'tree') {
                    riskLevels[obj] = "High Risk"; // High risk for large or close objects
                } else if (obj === 'bicycle' || obj === 'dog') {
                    riskLevels[obj] = "Medium Risk"; // Medium risk for smaller objects
                } else {
                    riskLevels[obj] = "Low Risk"; // Low risk for distant or less dangerous obstacles
                }
            });
            return riskLevels;
        }
    
        // Provide auditory feedback based on detected objects and their risk levels
        function provideAuditoryFeedback(objectCounts, riskLevels) {
            let feedbackMessage = "Detected objects: ";
            for (const [object, count] of Object.entries(objectCounts)) {
                const risk = riskLevels[object];
                feedbackMessage += `${count} ${object} (${risk}). `;
            }
            playAudioFeedback(feedbackMessage);
        }
    
        // Display detected objects on the screen
        function displayDetectedObjects(objectCounts, riskLevels) {
            detectedObjectsDiv.innerHTML = '';
            for (const [object, count] of Object.entries(objectCounts)) {
                const risk = riskLevels[object];
                const objectInfo = document.createElement('p');
                objectInfo.textContent = `${object}: ${count} detected - Risk: ${risk}`;
                detectedObjectsDiv.appendChild(objectInfo);
            }
        }
    
        // Start real-time object detection
        function startRealTimeDetection() {
            setInterval(() => {
                detectButton.click();  // Simulate clicking the Detect Objects button every 7 seconds
            }, 10000);
        }
    </script>
</body>
</html>
